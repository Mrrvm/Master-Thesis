%!TEX root = ../dissertation.tex

\section{Epipolar Geometry}
\label{cha2:epipolar}

Epipolar geometry provides an alternative yet powerful tool to obtain image transformations using various different approaches. It describes the relation between two images, before and after a transformation, through a 3x3 singular, non-invertible, matrix called the \textbf{essential matrix}, \textbf{$E$}, if the camera matrix is known, or the \textbf{fundamental matrix}, \textbf{$F$}, otherwise. These matrices are singular because they express an under-constrained relationship between a point in one image and its possible location in the other image, which is not unique due to depth ambiguity. The essential matrix is the product of a rotation matrix and a \gls{skews}, whose determinant is zero, as it will be shown below. If a point in the real world, $M$, is projected as a point $\mathbf{{m}_1}$ in the first image, and point $\mathbf{{m}_2}$ in the second, then those points satisfy the epipolar relation

\begin{equation}
\label{sec2:eq:epipolar}
\mathbf{\tilde{m}_2}^T F \mathbf{\tilde{m}_1} = 0,
\end{equation}

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{images/epipolargeo.png}
	\caption[Epipolar geometry]{Epipolar geometry. The two small vertical planes correspond to the image planes after the rotation and translation of the camera, $R$ and $\bf t$, respectively. $c_1$ and $c_2$ are the centers of projection before and after the transformation. $M$ is the fixed point gazed at in the real world. $\bf m_1$ and $\bf m_2$ are the projections of point $M$ into the respective image planes, whose rays are lying on the plane $L$. $\bf l_{e1}$ and $\bf l_{e2}$ are the epipolar lines, that also lie on the plane and $\bf e_1$ and $\bf e_2$ are the epipoles.}
	\label{sec2:fig:epipolargeo}
\end{figure}

which can be easily deduced with projective geometry. In Figure \ref{sec2:fig:epipolargeo}, $c_1$ and $c_2$ are the centers of projection before and after the camera has been displaced by $(R, \mathbf{t})$. Given the point $\bf m_1$ on the first image, its correspondence, $\bf m_2$, in the second image is constrained to a line, the epipolar line, $\bf l_{e2}$. The latter is defined as the intersection of the plane $L$ and the second image plane. Furthermore, plane $L$ is delineated by the two centers of projection and $\bf m_1$. The epipoles, $\bf e_1$ and $\bf e_2$, are born from the intersection of the line $c_1 - c_2$ with the epipolar lines, $\bf l_{e1}$ and $\bf l_{e2}$. 

\subsection{Projective geometry concepts}

Now, before one may understand the upcoming deductions, it is important to first understand the following concepts.
\subsubsection{Representation of lines in \gls{homo}}
A line in a plane is represented by $a x + b y + c = 0$, which can also be defined by a vector $( a , b , c ) ^T$. For any non-zero constant, $k$, the vectors  $( a , b , c ) ^T$ and $k(a , b , c ) ^T$ represent the same line and are equivalent. An equivalence class of vectors is known as an homogenous vector. 
\subsubsection{Point lying on a line}
A point $\mathbf { p } = ( p_1 , p_2 ) ^ T$ lies on a line $\mathbf {\tilde{l}} = ( a , b , c ) ^ { T }$, if and only if $a p_1 + b p_2 + c = 0$, which can be written as $( p_1 , p_2 , 1 ) ( a , b , c ) ^T = \mathbf { \tilde{p} } ^T \mathbf {\tilde{l}} = \mathbf {\tilde{l}} ^T \mathbf { \tilde{p} } = 0$.
\subsubsection{Line joining points}
A line passing through any two points $\mathbf{\tilde{p}}$ and $\mathbf{\tilde{q}}$ can be defined by the cross-product of those points as $\mathbf{\tilde{l}} = \mathbf{\tilde{p}} \times \mathbf{\tilde{q}}$.
\subsubsection{Cross product's \gls{skews} representation}
The previous cross product, $\mathbf{\tilde{l}} = \mathbf{\tilde{p}} \times \mathbf{\tilde{q}}$, can be written as $\mathbf{\tilde{l}} = [\mathbf{\tilde{p}}]_{\times} \mathbf{\tilde{q}}$, where $[\mathbf{p}]_{\times}$ is defined as
\begin{equation}
\label{sec2:eq:crossp}
\left[ \mathbf{p} \right]_ { \times } =  \left[ \begin{array} { c c c } { 0 } & { - p_ { 3 } } & { p_{ 2 } } \\ { p_{ 3 } } & { 0 } & { - p_{ 1 } } \\ { - p _ { 2 } } & { p_ { 1 } } & { 0 } \end{array} \right].
\end{equation}

\subsection{Deducing the fundamental matrix algebraically}

Having said this,
\begin{enumerate}
	\item there is an homographic mapping via $L$ plane from the points of the first to the second image, characterized by $\mathbf{\tilde{m}_2} = H_M \mathbf{\tilde{m}_1}$;
	\item because $\mathbf{m_2}$ lies on $\mathbf{\tilde{l}_{e_2}}$, then $\mathbf{ \tilde{m}_2 } ^T \mathbf{\tilde{l}_{e_2}} = 0$;
	\item and since $\mathbf { e_2 }, \mathbf { m_2 } \in \mathbf{\tilde{l}_{e_2}}$, then $\mathbf{\tilde{l}_{e_2}} = [\mathbf{\tilde{e}_2}]_{\times} \mathbf{\tilde{m}_2}$.
\end{enumerate}
From 1) and 3), 
\begin{equation}
\label{ggg}
\mathbf{\tilde{l}_{e_2}} = [\mathbf{\tilde{e}_2}]_{\times} H_M \mathbf{\tilde{m}_1} 
\end{equation}
can be deduced and using conclusion 2) and (\ref{ggg}),
\begin{equation}
\label{sec2:eq:fundm}
\mathbf{\tilde{m}_2}^T \mathbf{\tilde{l}_{e_2}} = 0 = \mathbf{\tilde{m}_2}^T [\mathbf{\tilde{e}_2}]_{\times} H_M \mathbf{\tilde{m}_1}  = \mathbf{\tilde{m}_2}^T F \mathbf{\tilde{m}_1},
\end{equation}
where $F$, the fundamental matrix, is an homogeneous matrix of rank-2 (since $[\mathbf{\tilde{e}_2}]_{\times}$ is rank-2 and $H_M$ is rank-3) with 7 degrees of freedom, and $det(F) = 0$.

\subsection{Deducing the fundamental matrix from camera motion}
Another way of obtaining this relation is through the camera motion.
If the point in the real world is expressed in the eye's perspective before rotating, $M_1$, under the camera model studied in section \ref{cha2:features}, (\ref{sec2:eq:eproj1}) and ((\ref{sec2:eq:eproj2}) are true.
\begin{align}
\label{sec2:eq:eproj1}
\lambda_1 \mathbf{\tilde{m}_1} = K [ I \ \mathbf{0} ] \tilde{M_1}, \\
\label{sec2:eq:eproj2}
\lambda_2 \mathbf{\tilde{m}_2} = K [ R \ \mathbf{t} ] \tilde{M_1}
\end{align}
For now, for the sake of simplicity, the intrinsics matrix will be considered the identity, $K= I$, and the scale factors $\lambda_1$ and $\lambda_2$ will be dropped. Hence, by eliminating $\tilde{M_1}$, the previous equations become
\begin{equation}
\label{sec2:eq:elimp}
\mathbf{\tilde{m}_2} = R   \mathbf{\tilde{m}_1} + \mathbf{t},
\end{equation}
and because the cross product of two vectors is orthogonal to them both,  
\begin{align}
	\label{sec2:eq:fundm1}
	\mathbf{\tilde{m}_2}^T \cdot ( \mathbf{\tilde{m}_2} \times \mathbf{t}) = 0 \\
	\label{sec2:eq:fundm2}
	\text{and } ( \mathbf{\tilde{m}_2}^T\cdot((R  \mathbf{\tilde{m}_1} + \mathbf{t}) \times \mathbf{t}) = 0.
\end{align}
Therefore, the fundamental matrix, $F$, can be determined by 
\begin{equation}
\label{sec2:eq:fundm3}
\begin{aligned}
\mathbf{\tilde{m_2}}^T [\mathbf{t}]_\times R \mathbf{\tilde{m_1}} = 0 \\
\mathbf{\tilde{m_2}}^T F \mathbf{\tilde{m_1}} = 0.
\end{aligned}
\end{equation}
When the intrinsic parameters are not the identity matrix, then 
\begin{equation}
\begin{aligned}
\label{hhh}
\mathbf{\tilde{m_2}}^T K^{-T} E K^{-1} \mathbf{\tilde{m_1}} = 0 \\
\text{and finally }
F = K^{-T}  E K^{-1},
\end{aligned}
\end{equation}
where $E$ is the essential matrix.

\subsection{Estimating the fundamental matrix}
\label{einvonrev}
In such wise, the question now is how to determine $F$, and consequently the rotation, given two images with matching points. With the last-mentioned referred to as $\mathbf{m_{1}} = [u_{1} \ v_{1}]^T$ and $\mathbf{m_{2}} = [u_{2}  \ v_{2}]^T$, the epipolar equation (\ref{sec2:eq:epipolar}) can then be written as
\begin{equation}
\begin{aligned}
\begin{bmatrix}
u_2 & v_2 & 1
\end{bmatrix}
\begin{bmatrix}
f_{11} & f_{12} & f_{13}  \\
f_{21} & f_{22} & f_{23}  \\
f_{31} & f_{32} & f_{33} 
\end{bmatrix}
\begin{bmatrix}
u_{1} \\ v_{1} \\ 1
\end{bmatrix}\\
=
\begin{bmatrix}
f_{11} u_1 u_2 + f_{12} v_1 u_2  + f_{13}u_2 + f_{21} u_1 v_2  + f_{22} v_1 v_2  + f_{23}v_2  + f_{31} u_1 + f_{32} v_1 + f_{33} 
\end{bmatrix}\\
=
\begin{bmatrix}
u_1u_2 \ v_1u_2 \ u_2 \ u_1v_2 \ v_1v_2 \  v_2 \ u_1 \ v_1 \ 1 
\end{bmatrix}
\begin{bmatrix}
f_{11} \ f_{12} \ f_{13} \ f_{21} \ f_{22} \ f_{23} \ f_{31} \ f_{32} \ f_{33}
\end{bmatrix}^T\\
= \mathbf{u} \cdot \mathbf{f}\\ = 0
\end{aligned}
\end{equation}
For $n$ sets of points the expression becomes 
\begin{equation}
\label{sec2:eq:nsets}
U f = 0,
\end{equation}
where $U = \left[ \mathbf{u_ { 1 }} , \cdots , \mathbf{u_ { n }} \right] ^ { T }$. 
This linear homogeneous equation, and the rank-2 constraint over $F$, that restrains the matrix to 7 degrees of freedom (since $F$ is also defined up a scalar factor), will permit its unique identification. 
Hence, the estimation of $F$ may be done using only 7 point matches, or by using 8 or more if enough data points are available. In the latter case, the solution produced is in general unique, and there are several techniques to obtain it. In Zhang 1996's review on the issue \cite{detep}, the conclusion was that linear techniques are usually sensitive to noise and not very stable, because they ignore the constraints of $F$ and the minimization criterion is not physically meaningful. However, the results could be improved by using normalized data points instead of pixel coordinates. 

Nevertheless, non-linear optimization techniques seem to yield better results to the estimation problem of $F$. Three nonlinear algorithms are mentioned in the review paper: (i) a minimization of the epipolar error, (ii) a minimization of the re-projection errors (iii) and a gradient-based technique. The second one is the most time-consuming, thus not recommended. From the other two most promising approaches, the first seems to give the worst results and the last algorithm has been proposed to give the best results in the least amount of computational time. 

Algorithm (i) minimizes the distances between points and their corresponding epipolar lines,
\begin{equation}
\label{cha2:sec3:eq:mee}
	\min_{\mathbf{F}} \sum_{i}\left(
	d^{2}(\widetilde{\mathbf{m}}_{2i}, \widetilde{\mathbf{l}}_{e_2i})
	+
	d^{2}(\widetilde{\mathbf{m}}_{1i}, \widetilde{\mathbf{l}}_{e_1i})\right),
\end{equation}
where $i=1,...,n$ with $n$ being all the point matches and for a generic point in the first image
\begin{equation}
\label{cha2:sec3:eq:meed}
	d(\widetilde{\mathbf{m}}_1, \widetilde{\mathbf{l}}_{e_1}) = \frac{\widetilde{\mathbf{m}}_1^T \widetilde{\mathbf{l}}_{e_1}}{\sqrt{l_{e_{1_x}}^2+l_{e_{1_y}}^2}}.
\end{equation}
Algorithm (ii) minimizes 
\begin{equation}
\label{cha2:sec3:eq:al3}
	\min_{\mathbf{F}}\sum_{i}
	\left(
	\left\|\widetilde{\mathbf{m}}_{1i}-\mathbf{h}_1(\mathbf{f}, M_i)\right\|^2
	+
	\left\|\widetilde{\mathbf{m}}_{2i}-\mathbf{h}_2(\mathbf{f}, M_i)\right\|^2\right),
\end{equation}
where $M_i$ with $i=1,...,n$ are the $n$ points in space, while $\mathbf{h}_1(\mathbf{f}, M_i)$ and $\mathbf{h}_2(\mathbf{f}, M_i)$ are the functions that project the points in space into the first and second image plane, respectively, given the fundamental matrix represented as a vector by $\mathbf{f}$.

\subsection{\acrlong{grat}}

Minimizing $ \sum_i (\mathbf{\widetilde{m_i}}'^T F \mathbf{\widetilde{m_i}})^2$ doesn't yield a good result because the variance of each $i$ term is not the same and the least-squares technique produces an optimal solution if each term has the same variance.
So one possibility, given by algorithm (iii), is
\begin{equation}
\min_F \sum_i \frac{ (\mathbf{\widetilde{\mathbf{m}}_{2i}}^T F \widetilde{\mathbf{m}}_{1i})^2}{\sigma_i^2},
\end{equation}
where $i=1,...,n$ and $\sigma_i^2$ is the variance given by 
\begin{equation}
\sigma_i^2 = \sigma [l_{{e1i}_x}^2 + l_{{e1i}_y}^2 + l_{{e2i}_x}^2 + l_{{e2i}_y}^2].
\end{equation}
Because multiplying each term by a constant makes no difference, $\sigma$ can be dropped. $\sigma_i$ is what originates the name as it is the  epipolar relation gradient.

\subsection{Factorization of the essential matrix}

Once the fundamental matrix is obtained through one of those methods, assuming the intrinsic parameters are known, which is the case for this project, where the setup is only one camera, the essential matrix may be obtained by $E = K^{T}  F K$ as seen on (\ref{hhh}).
From here, it's possible to retrieve the camera matrix, $P = [R \ | \ \mathbf{t}]$, since $E = [\mathbf{t}]_\times R$. 

A $3x3$ matrix is an essential matrix if and only if two of its singular values are equal, and the third is zero. This is easily proven by the decomposition of $E = SR$, where $S$ is a \gls{skews}.
Considering the matrices 
\begin{equation}
\mathrm { W } = \left[ \begin{array} { c c c } { 0 } & { - 1 } & { 0 } \\ { 1 } & { 0 } & { 0 } \\ { 0 } & { 0 } & { 1 } \end{array} \right] \quad \text { and } \quad \mathrm { Z } = \left[ \begin{array} { c c c } { 0 } & { 1 } & { 0 } \\ { - 1 } & { 0 } & { 0 } \\ { 0 } & { 0 } & { 0 } \end{array} \right],
\end{equation}
where $W$ is orthogonal and $Z$ is a \gls{skews}, $S$ may be written as $S = kUZU^T$\footnote{A proof of this is given in Result A4.1 of R. Hartley and A. Zisserman,Multiple View Geometry in Computer Vision \cite{multiview}}, where $U$ is orthogonal and $Z = \operatorname{diag}(1,1,0)W$, up to sign. Thus, $S = U \operatorname { diag } ( 1,1,0 ) WU^T$, up to scale, and 
\begin{equation}
E = SR = U \operatorname { diag } ( 1,1,0 ) \left( WU^T R \right) = U \operatorname { diag } ( 1,1,0 ) V^T,
\end{equation}
proving the initial statement.

Because the singular values have to be equal, the \acrshort{svdd} of $E$ is not unique, in fact 
\begin{equation}
\label{gf}
E = U \operatorname { diag } ( 1,1,0 ) V ^ { T },
\end{equation}
or 
\begin{equation}
E = U \operatorname { diag } ( 1,1,0 ) ( - V ) ^ { T }.
\end{equation} 
Considering (\ref{gf}), because
\begin{equation}
\begin{aligned} 
Z W = \operatorname { diag } ( 1,1,0 ) \\ 
\text{and} \
Z W ^ { T } = - \operatorname { diag } ( 1,1,0 ) ,
\end{aligned}
\end{equation}
$E=SR$ may be decomposed into two forms,
\begin{equation}
\label{ccha}
S = - U Z U ^ { T } , \quad R = U W ^ { T } V ^ { T },
\end{equation}
or
\begin{equation}
\label{ccha2}
S = U Z U ^ { T } , \quad R = U W V ^ { T }.
\end{equation}
The matrix $R$ on (\ref{ccha}) is a rotation, since it is orthogonal,
\begin{equation}
R ^ { T } R = \left( U W ^ { T } V ^ { T } \right) ^ { T } U W ^ { T } V ^ { T } = V W U ^ { T } U W ^ { T } V ^ { T } = I,
\end{equation}
and 
\begin{equation}
\operatorname { det } \left( U W ^ { T } V ^ { T } \right) = \operatorname { det } ( U ) \operatorname { det } \left( W ^ { T } \right) \operatorname { det } \left( V ^ { T } \right) = \operatorname { det } ( W ) \operatorname { det } \left( U V ^ { T } \right) = 1,
\end{equation}
which are enough conditions to prove it. Furthermore, $S$ is a \gls{skews} because,
\begin{equation}
- S^ { T } = \left( U Z U ^ { T } \right) ^ { T } = U Z ^ { T } U ^ { T } = - U Z U ^ { T } = S.
\end{equation}
The same applies to (\ref{ccha2}).\footnote{C. Olsson. \href{http://www.maths.lth.se/matematiklth/personal/calle/datorseende13/notes/forelas6.pdf}{http://www.maths.lth.se/matematiklth/personal/calle/datorseende13/notes/forelas6.pdf}. Lund Institue of Technology. Computer Vision 2013. Lecture 6.} A proof that these are the only solutions is given in Result 9.18 of R. Hartley and A. Zisserman \cite{multiview}.

Now regarding the translation, since $S \mathbf{t} = [\mathbf{t}]_{\times}\mathbf{t} = 0$, it follows that $t = U (0, 0, 1)^T = u_3$, the last column of $U$, which can be explained by the following. Assuming $S \mathbf{t} = U Z U^T \mathbf{t} = 0$, $Z U^T \mathbf{t}$ should be equal to zero to satisfy the equation. Because $Z$ is an orthogonal matrix,
\begin{equation}
Z U^T \mathbf{t} = \left[ \begin{array} { c c c } { 0 } & { 1 } & { 0 } \\ { - 1 } & { 0 } & { 0 } \\ { 0 } & { 0 } & { 0 } \end{array} \right] U^T \mathbf{t}  = \left[ \begin{array} { c c c } { 0 } & { 1 } & { 0 } \\ { - 1 } & { 0 } & { 0 } \\ { 0 } & { 0 } & { 0 } \end{array} \right] \left[ \begin{array} { c } { 0 } \\ { 0} \\ s \end{array} \right] = 0,
\end{equation}
where $s$ is any non-zero constant, such as $1$. Therefore, $\mathbf{t} = U [0 \ 0 \ 1]^T = u_3$, as U is orthogonal as well.\\
Finally, due to the lack of uniqueness of the \acrshort{svdd}, there are 4 possible solutions for the camera matrix,
\begin{equation}
P = \left[UWV^T | + u_{ 3 } \right] \quad \text { or } \quad \left[ UWV^T | - u_ { 3 } \right] \quad \text { or } \quad \left[ UW^T V^T | + u_ { 3 } \right] \quad \text { or } \quad \left[ UW^T V^T |- u _ { 3 } \right],
\end{equation}
that are represented by (a), (b), (c) and (d), respectively, on Figure \ref{sec2:fig:ep4}. 

The real world point is only in front of both cameras in one of the four solutions, thus it is enough to use a single point to decide which of the different solutions produces the correct camera matrix. \cite{multiview}

To summarize, the steps for obtaining the projective transformation from epipolar geometry are:

\begin{enumerate}
	\item Determining the fundamental matrix, $F$, using one of the algorithms described on section \ref{einvonrev};
	\item Obtain the essential matrix, $E$, from the intrinsic parameters (which is possible in this case);
	\item Retrieve the four possible solutions for $P = [R \ | \ \mathbf{t}]$ by doing a \acrshort{svdd} decomposition on $E$;
	\item Choose the feasible solution.
\end{enumerate}

\begin{figure}[ht]
	\centering
	\includegraphics[width=10cm]{images/ep4sols.png}
	\caption[Four possible solutions retrieved from $E$]{Four possible solutions retrieved from the essential matrix $E$. The points A and B correspond to the centers of projection before and after rotating. Between the right side, (a) and (c), and the left side, (b) and (d), figures, there is a translation direction inversion. Between top, (a) and (b), and bottom, (c) and (d), figures, there is a rotation of 180 degrees around the baseline. \cite{multiview}}
	\label{sec2:fig:ep4}
\end{figure}

\subsection{Pure rotation}

As a disadvantage of epipolar geometry, if the eye's movement is not constrained by a translation component, the epipolar relation will not work, since $[\mathbf{t}]_\times$ would be a $3x3$ matrix of zeros and, consequently, $E = [\mathbf{t}]_\times R$ would yield the same, making it unfeasible to retrieve the rotation.\\

When doing feature detection and matching, wrongly matched pairs of points between the two images, or points with large location errors, could severely affect the precision of the estimation of $F$. The reason for this is that all methods are least-square techniques that assume the noise which corrupts the data has zero mean. Hence, it is relevant to look into techniques of robust estimation.

